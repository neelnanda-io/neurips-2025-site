content: "## Workshop Goals\n\nThe mechanistic interpretability field benefits from\
  \ a rich diversity of approaches\u2014from rigorous mathematical analysis to large-scale\
  \ empirical studies, from reverse-engineering a model via bottom-up circuit analysis,\
  \ to assisting behavioral analysis via top-down analysis of model representations.\
  \ But all are unified by the belief that there is meaning and structure to be found\
  \ inside neural networks, and that this is worth studying.\n\n\nThis diversity reflects\
  \ the field's breadth and the many valid paths toward understanding neural networks.\
  \ But those in these different sub-communities often lack natural venues to meet.\
  \ Our workshop aims to:\n\n\n* **Showcase cutting-edge research\_across all approaches\
  \ to mechanistic interpretability**\n\n* **Foster cross-pollination\_between different\
  \ methodological traditions**\n\n* **Identify convergent insights\_emerging from\
  \ diverse research programs**\n\n* **Build understanding between different perspectives,\
  \ research communities, and terminologies**\n\n* **Welcome newcomers\_by providing\
  \ clear entry points into the field**\n\n**We hope to explore points of active debate\
  \ in the field including:**\n\n\n* **How researchers should prioritise between gathering\
  \ evidence via rigorous qualitative analysis vs performance on benchmarks/real-world\
  \ tasks**\n\n* **What are the implications of new paradigms like reasoning models\
  \ for the field\u2019s priorities?**\n\n* **Whether the field\u2019s north star\
  \ should be complete reverse engineering, achieving high-level understanding, or\
  \ something else entirely**\n\n* **How reliable or useful are popular methods such\
  \ as [sparse](https://www.google.com/url?q=https://transformer-circuits.pub/2023/monosemantic-features/index.html&sa=D&source=editors&ust=1752155398416188&usg=AOvVaw2rxAH9D84qffH1-p7Un972)\_\
  [autoencoders](https://www.google.com/url?q=https://adamkarvonen.github.io/machine_learning/2024/06/11/sae-intuitions.html&sa=D&source=editors&ust=1752155398416346&usg=AOvVaw022B2lyD5oXfVKss9jX5JT),\
  \ and how much should we [prioritize](https://www.google.com/url?q=https://deepmindsafetyresearch.medium.com/negative-results-for-sparse-autoencoders-on-downstream-tasks-and-deprioritising-sae-research-6cadcfc125b9&sa=D&source=editors&ust=1752155398416598&usg=AOvVaw2N-FhFO3pGIZuLJ286hGBd)\_\
  them compared to other research directions?**\n\n* **The relative merits of a perspective\
  \ of curiosity driven basic science vs working towards specific goals**\n\n* **How\
  \ important are unsupervised techniques with the potential to surprise us, such\
  \ as [transcoders](https://www.google.com/url?q=https://transformer-circuits.pub/2025/attribution-graphs/biology.html&sa=D&source=editors&ust=1752155398417129&usg=AOvVaw1FdQeuOS1ngGei2U6ELobz),\
  \ compared to simple\_supervised techniques such as [probing](https://www.google.com/url?q=https://arxiv.org/abs/2102.12452&sa=D&source=editors&ust=1752155398417332&usg=AOvVaw3JevDgcvD-KHgW2HVA8eUq).**\n\
  \n**In this workshop, we hope to bring together researchers from across these many\
  \ perspectives and communities\u2014along with skeptics, experts in adjacent fields,\
  \ and those simply curious to learn more\u2014to facilitate healthy discussion and\
  \ move towards a greater mutual understanding as a field.**\n\n\n**Through our [call\
  \ for papers](https://www.google.com/url?q=https://mechinterpworkshop.com/cfp/&sa=D&source=editors&ust=1752155398417840&usg=AOvVaw1xnhcx5Fqu_Ubw3ii0nFHN),\
  \ we hope to facilitate the sharing of work in this fast-moving field, across all\
  \ of these axes, and especially work that helps to bridge these gaps.**\n**We welcome\
  \ any submissions that seek to further our ability to use the internals of models\
  \ to achieve understanding, regardless of how unconventional the approach may be.\
  \ Please see the [call for papers page](https://www.google.com/url?q=https://mechinterpworkshop.com/cfp/&sa=D&source=editors&ust=1752155398418298&usg=AOvVaw1oV6W380gZD9Pm3XNwOMUS)\_\
  for further details and particular topics of interest.**\n\n\n**We welcome attendees\
  \ from all backgrounds, regardless of your prior research experience or if you have\
  \ work published at this workshop. Note that while you do not need to be registered\
  \ for the NeurIPS main conference to attend this workshop, you do need to be registered\
  \ for the NeurIPS workshop track. No further registration needed, seating is first-come\
  \ first-served.**\n\n\n## Learning More\n\n**Here are some resources you may find\
  \ useful for learning more about the mechanistic interpretability field and performing\
  \ research:**\n\n\n* **We recommend starting with the review paper [Open Problems\
  \ in Mechanistic Interpretability](https://www.google.com/url?q=https://arxiv.org/abs/2501.16496&sa=D&source=editors&ust=1752155398419205&usg=AOvVaw1TdjMD30_ILeebAhu11dTq)\_\
  for an overview of the field**\n\n* **[Ferrando et al](https://www.google.com/url?q=https://arxiv.org/abs/2405.00208&sa=D&source=editors&ust=1752155398419339&usg=AOvVaw1oHPw1s63GV68s6luIqfSW)\_\
  is a good primer on the key techniques of the field**\n\n* **The [ARENA coding tutorials](https://www.google.com/url?q=https://arena-chapter1-transformer-interp.streamlit.app/&sa=D&source=editors&ust=1752155398419509&usg=AOvVaw0B1JgyVyTlQo3N02x0-Xbk)\_\
  are a great place to learn how to implement these techniques in practice**\n\n\n\
  \n**Resources for doing research**\n\n\n* **Popular libraries include: [TransformerLens](https://www.google.com/url?q=https://github.com/TransformerLensOrg/TransformerLens&sa=D&source=editors&ust=1752155398419795&usg=AOvVaw1tEeLq-583_j75tZbBF-3_)\_\
  (PyTorch, best for <=9B models), [nnsight](https://www.google.com/url?q=https://github.com/ndif-team/nnsight&sa=D&source=editors&ust=1752155398419900&usg=AOvVaw1nKE78a3nxJhD5bQ6B33dl)\_\
  (PyTorch, more flexible and scales better), [Penzai](https://www.google.com/url?q=https://github.com/google-deepmind/penzai&sa=D&source=editors&ust=1752155398420013&usg=AOvVaw19k17n8wvbHgWGuU-WE0Hv)\_\
  (Jax)**\n\n* **The [Mechanistic Interpretability Benchmark](https://www.google.com/url?q=https://mib-bench.github.io/&sa=D&source=editors&ust=1752155398420163&usg=AOvVaw0etYyjKPqpQuTQf-YclKIY)**\n\
  \n* **The [Gemma Scope Sparse Autoencoders](https://www.google.com/url?q=https://arxiv.org/abs/2408.05147&sa=D&source=editors&ust=1752155398420298&usg=AOvVaw3vAd89PL-6R_6YtGHTZBS0)\_\
  ([interactive tutorial](https://www.google.com/url?q=http://neuronpedia.org/gemma-scope&sa=D&source=editors&ust=1752155398420393&usg=AOvVaw0bxA9Wb82WlgQtV131KVPE))**\n\
  \n\n\n**Relevant online communities:**\n\n\n* **[Open Source Mechanistic Interpretability\
  \ Slack](https://www.google.com/url?q=http://neelnanda.io/osmi-slack-invite&sa=D&source=editors&ust=1752155398420649&usg=AOvVaw1l2kcIF6tLtwbAwwXMA7Dg)**\n\
  \n* **[Mechanistic Interpretability Discord](https://www.google.com/url?q=https://discord.gg/ysVfhCfCKw&sa=D&source=editors&ust=1752155398420798&usg=AOvVaw3Ah_RjXdHoBmUvlO7C52LQ)**\n\
  \n* **[Eleuther Discord](https://www.google.com/url?q=https://discord.gg/nHS4YxmfeM&sa=D&source=editors&ust=1752155398420922&usg=AOvVaw3RVwX60aHWi1swCOZ3fhkg)**\n\
  \n\n"
