---
title: "Schedule"
---

The workshop will be held on **Sunday, December 7, 2025** at the NeurIPS venue in San Diego, California (Upper Level Room 30A-E).

## Workshop Program

| Time | Activity |
|------|----------|
| 8:00am – 9:00am | *Socializing* |
| 9:00am – 9:15am | *Coffee break* |
| 9:15am – 9:30am | Opening remarks |
| 9:30am – 10:00am | **Been Kim** · *Towards a Pareto Frontier of Interpretability: 15 Years of Research in 15 Mins* |
| 10:00am – 10:30am | **Sarah Schwettmann** · *Scalable End-to-End Interpretability* |
| 10:30am – 11:00am | *Coffee break* |
| 11:00am – 11:30am | [Spotlight talks (session 1)](/spotlights/#morning) |
| 11:30am – 12:30pm | [Posters (session 1)](/posters-1/) |
| 12:30pm – 1:30pm | *Lunch break* |
| 1:30pm – 2:00pm | [Spotlight talks (session 2)](/spotlights/#afternoon) |
| 2:00pm – 3:00pm | [Posters (session 2)](/posters-2/) |
| 3:00pm – 3:30pm | *Coffee break* |
| 3:30pm – 4:00pm | **Chris Olah** (Remote) · *Reflections on Interpretability* |
| 4:00pm – 5:00pm | Invited lightning talks |

### Invited Lightning Talks

| Speaker | Title |
|---------|-------|
| Ekdeep Singh Lubana <span class="affiliation">(Goodfire)</span> | *What is the Right Basis for Computation?* ([slides](https://docs.google.com/presentation/d/113O3P30gYmBzSkpUaovpqS5jiECbKSO-51G1IV8C4w8/edit?usp=sharing)) |
| Adam Belfki <span class="affiliation">(NDIF / Northeastern University)</span> | *Infrastructure for Your Interpretability Research* ([slides](https://docs.google.com/presentation/d/1rMHLso3bq1dyrScyvFvJHzjBgfQrN-o2qDUaF4QzPPE/edit?usp=sharing)) |
| Josh Engels <span class="affiliation">(Google DeepMind)</span> | *A Pragmatic Vision for Interpretability* ([slides](https://docs.google.com/presentation/d/1JmCvSiHZkr6ykX3WDEFHGHTGNpoSAR03x057cWhuuyA/edit?usp=sharing)) |
| Rowan Wang <span class="affiliation">(Anthropic)</span> | *Just Ask the Model: Interpreting Models with Clever Prompting* ([slides](https://docs.google.com/presentation/d/1A0-EU-as_-81143IaBXjNAhA0DWK0Bd5xJe4H1xrsdE/edit?usp=sharing)) |
| Sheridan Feucht <span class="affiliation">(Northeastern University)</span> | *Equifinality: There's Often Multiple Explanations* ([slides](https://docs.google.com/presentation/d/1K8r2zD1lmFQGirQJCGEY8r_S8qYB5zK4X40BJiVZlTI/edit?usp=sharing)) |
| Uzay Macar <span class="affiliation">(Anthropic Fellows)</span> | *Reasoning Model Interpretability Needs New Techniques* ([slides](https://docs.google.com/presentation/d/1k-OdiE5Ifaj4Qi5iiTOjrs2xzcBDWHRiyVTWo3V5zgw/edit?usp=sharing)) |
| Leo Gao <span class="affiliation">(OpenAI)</span> | *An Ambitious Vision for Interpretability* |
| Satvik Golechha & Sid Black <span class="affiliation">(UK AISI)</span> | *Auditing Games for Sandbagging* ([slides](https://docs.google.com/presentation/d/1sgM8Y9kl6gfLWiBFCZ0l1yxTDnjYVM7kcfwnH9Yd1lo/edit?usp=sharing)) |
| Bartosz Cywinski <span class="affiliation">(MATS)</span> | *How Model Organisms Can Enable Useful Interpretability Studies* ([slides](https://docs.google.com/presentation/d/1eF_u2oWSlICljzRNKLYSa8IZonkYhVgWbzGuuhxoghY/edit?usp=sharing)) |
| David Bau <span class="affiliation">(Northeastern University)</span> | *In Defense of Curiosity* ([slides](https://docs.google.com/presentation/d/1v_b9fLqrvWap3Gas8fVhrPn8tbzQttxXhFrWv2PS0vw/edit?usp=sharing)) |
| Jake Mendel <span class="affiliation">(Coefficient Giving)</span> | *How to Get Funding for Your Interpretability Research* |
